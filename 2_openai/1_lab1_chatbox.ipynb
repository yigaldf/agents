{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 2 Day 1\n",
    "\n",
    "And now! Our first look at OpenAI Agents SDK\n",
    "\n",
    "You won't believe how lightweight this is.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/tools.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">The OpenAI Agents SDK Docs</h2>\n",
    "            <span style=\"color:#00bfff;\">The documentation on OpenAI Agents SDK is really clear and simple: <a href=\"https://openai.github.io/openai-agents-python/\">https://openai.github.io/openai-agents-python/</a> and it's well worth a look.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The imports\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from agents import Agent, Runner, trace\n",
    "import gradio as gr\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The usual starting point\n",
    "\n",
    "load_dotenv(override=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make an agent with name, instructions, model\n",
    "\n",
    "agent = Agent(name=\"Jokester\", instructions=\"You are a joke teller\", model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the joke with Runner.run(agent, prompt) then print final_output\n",
    "\n",
    "async def ask_questions(message):\n",
    "    with trace(\"Telling a joke\"):\n",
    "        result = await Runner.run(agent, message)\n",
    "        return result.final_output  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7893\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7893/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo = gr.Interface(\n",
    "    fn=ask_questions,\n",
    "    inputs=gr.Textbox(label=\"Enter message\"),\n",
    "    outputs=gr.Textbox(label=\"Response\"),\n",
    ")\n",
    "\n",
    "demo.launch(inline=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7894\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7894/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import asyncio\n",
    "\n",
    "# Your async function\n",
    "async def ask_questions(message):\n",
    "    with trace(\"Telling a joke\"):\n",
    "        result = await Runner.run(agent, message)\n",
    "        return result.final_output\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "\n",
    "# Wrapper to call async from sync Gradio interface\n",
    "def gradio_interface(message, history):\n",
    "    response = asyncio.run(ask_questions(message))\n",
    "    chat_history.append({\"user\": message, \"agent\": response})\n",
    "\n",
    "    history += f\"\\nUser: {message}\\nAgent: {response} \\n\"\n",
    "    return response, history\n",
    "\n",
    "# Gradio UI\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## 🤖 Async Chat Interface\")\n",
    "\n",
    "    msg_input = gr.Textbox(label=\"Your Message\")\n",
    "    btn = gr.Button(\"Send\")\n",
    "\n",
    "    output = gr.Textbox(label=\"Agent's Response\")\n",
    "    \n",
    "    history_box = gr.Textbox(label=\"Chat History\", lines=10, interactive=False)\n",
    "\n",
    "\n",
    "    btn.click(\n",
    "        fn=gradio_interface,\n",
    "        inputs=[msg_input, history_box],\n",
    "        outputs=[output, history_box]\n",
    "    )\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7890\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7890/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import asyncio\n",
    "\n",
    "# Your async function\n",
    "async def ask_questions(message):\n",
    "    with trace(\"Telling a joke\"):\n",
    "        result = await Runner.run(agent, message)\n",
    "        return result.final_output\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "\n",
    "# Wrapper to call async from sync Gradio interface\n",
    "def gradio_interface(message):\n",
    "    response = asyncio.run(ask_questions(message))\n",
    "    chat_history.append({\"user\": message, \"agent\": response})\n",
    "    formatted = \"\"\n",
    "    for turn in chat_history:\n",
    "        formatted += f\"User: {turn['user']}\\nAgent: {turn['agent']}\\n\\n\"\n",
    " \n",
    "    return response, formatted\n",
    "\n",
    "# Gradio UI\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## 🤖 Async Chat Interface\")\n",
    "\n",
    "    msg_input = gr.Textbox(label=\"Your Message\")\n",
    "    btn = gr.Button(\"Send\")\n",
    "\n",
    "    output = gr.Textbox(label=\"Agent's Response\")\n",
    "    \n",
    "    history_box = gr.Textbox(label=\"Chat History\", lines=10, interactive=False)\n",
    "\n",
    "\n",
    "    btn.click(\n",
    "        fn=gradio_interface,\n",
    "        inputs=[msg_input],\n",
    "        outputs=[output, history_box]\n",
    "    )\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z9/yt34ddps7xx4bv4m4xb674g00000gn/T/ipykernel_6881/3507197931.py:71: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7896\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7896/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import asyncio\n",
    "import time\n",
    "from typing import List, Dict\n",
    "\n",
    "# Your async function\n",
    "async def ask_questions(message: str) -> str:\n",
    "    with trace(\"Telling a joke\"):\n",
    "        result = await Runner.run(agent, message)\n",
    "        return result.final_output\n",
    "\n",
    "# Global chat history\n",
    "chat_history: List[Dict[str, str]] = []\n",
    "\n",
    "def gradio_interface(message: str, history: List[List[str]]) -> tuple:\n",
    "    \"\"\"\n",
    "    Enhanced Gradio interface function with better error handling and formatting\n",
    "    \"\"\"\n",
    "    if not message.strip():\n",
    "        return history, history, \"\"\n",
    "    \n",
    "    try:\n",
    "        # Run the async function\n",
    "        response = asyncio.run(ask_questions(message))\n",
    "        \n",
    "        # Update chat history\n",
    "        chat_history.append({\"user\": message, \"agent\": response, \"timestamp\": time.time()})\n",
    "        \n",
    "        # Update Gradio chat history format\n",
    "        history.append([message, response])\n",
    "        \n",
    "        return history, history, \"\"  # Clear input\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error: {str(e)}\"\n",
    "        history.append([message, error_msg])\n",
    "        return history, history, \"\"\n",
    "\n",
    "def clear_history():\n",
    "    \"\"\"Clear the chat history\"\"\"\n",
    "    global chat_history\n",
    "    chat_history = []\n",
    "    return [], []\n",
    "\n",
    "def export_history() -> str:\n",
    "    \"\"\"Export chat history as formatted text\"\"\"\n",
    "    if not chat_history:\n",
    "        return \"No chat history to export.\"\n",
    "    \n",
    "    formatted = \"=== Chat History Export ===\\n\\n\"\n",
    "    for i, turn in enumerate(chat_history, 1):\n",
    "        timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(turn[\"timestamp\"]))\n",
    "        formatted += f\"Turn {i} ({timestamp}):\\n\"\n",
    "        formatted += f\"User: {turn['user']}\\n\"\n",
    "        formatted += f\"Agent: {turn['agent']}\\n\"\n",
    "        formatted += \"-\" * 50 + \"\\n\\n\"\n",
    "    \n",
    "    return formatted\n",
    "\n",
    "# Enhanced Gradio UI\n",
    "with gr.Blocks(title=\"Async Chat Interface\", theme=gr.themes.Soft()) as demo:\n",
    "    gr.Markdown(\"\"\"\n",
    "    # 🤖 Async Chat Interface\n",
    "    \n",
    "    Chat with your async agent in real-time. Messages are processed asynchronously for better performance.\n",
    "    \"\"\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=3):\n",
    "            # Main chat interface using Gradio's built-in chatbot component\n",
    "            chatbot = gr.Chatbot(\n",
    "                label=\"Chat with Agent\",\n",
    "                height=400,\n",
    "                show_label=True,\n",
    "                avatar_images=[\"👤\", \"🤖\"]\n",
    "            )\n",
    "            \n",
    "            with gr.Row():\n",
    "                msg_input = gr.Textbox(\n",
    "                    label=\"Your Message\",\n",
    "                    placeholder=\"Type your message here...\",\n",
    "                    lines=2,\n",
    "                    scale=4\n",
    "                )\n",
    "                send_btn = gr.Button(\"Send 📤\", variant=\"primary\", scale=1)\n",
    "            \n",
    "            with gr.Row():\n",
    "                clear_btn = gr.Button(\"Clear Chat 🗑️\", variant=\"secondary\")\n",
    "                export_btn = gr.Button(\"Export History 📋\", variant=\"secondary\")\n",
    "        \n",
    "        with gr.Column(scale=1):\n",
    "            gr.Markdown(\"### Chat Controls\")\n",
    "            \n",
    "            stats_display = gr.Markdown(\"**Messages sent:** 0\")\n",
    "            \n",
    "            # Export area\n",
    "            export_output = gr.Textbox(\n",
    "                label=\"Exported History\",\n",
    "                lines=10,\n",
    "                interactive=False,\n",
    "                visible=False\n",
    "            )\n",
    "    \n",
    "    # Event handlers\n",
    "    def update_stats():\n",
    "        return f\"**Messages sent:** {len(chat_history)}\"\n",
    "    \n",
    "    def send_message(message, history):\n",
    "        result = gradio_interface(message, history)\n",
    "        return result + (update_stats(),)\n",
    "    \n",
    "    def clear_and_update():\n",
    "        clear_history()\n",
    "        return [], [], update_stats()\n",
    "    \n",
    "    def export_and_show():\n",
    "        exported = export_history()\n",
    "        return exported, gr.update(visible=True)\n",
    "    \n",
    "    # Button clicks\n",
    "    send_btn.click(\n",
    "        fn=send_message,\n",
    "        inputs=[msg_input, chatbot],\n",
    "        outputs=[chatbot, chatbot, msg_input, stats_display]\n",
    "    )\n",
    "    \n",
    "    # Enter key support\n",
    "    msg_input.submit(\n",
    "        fn=send_message,\n",
    "        inputs=[msg_input, chatbot],\n",
    "        outputs=[chatbot, chatbot, msg_input, stats_display]\n",
    "    )\n",
    "    \n",
    "    clear_btn.click(\n",
    "        fn=clear_and_update,\n",
    "        outputs=[chatbot, chatbot, stats_display]\n",
    "    )\n",
    "    \n",
    "    export_btn.click(\n",
    "        fn=export_and_show,\n",
    "        outputs=[export_output, export_output]\n",
    "    )\n",
    "\n",
    "    demo.launch()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now go and look at the trace\n",
    "\n",
    "https://platform.openai.com/traces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mport numpy as np\n",
    "import gradio as gr\n",
    "\n",
    "def sepia(input_img):\n",
    "    sepia_filter = np.array([\n",
    "        [0.393, 0.769, 0.189],\n",
    "        [0.349, 0.686, 0.168],\n",
    "        [0.272, 0.534, 0.131]\n",
    "    ])\n",
    "    sepia_img = input_img.dot(sepia_filter.T)\n",
    "    sepia_img /= sepia_img.max()\n",
    "    return sepia_img\n",
    "\n",
    "demo = gr.Interface(sepia, gr.Image(), \"image\")\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
